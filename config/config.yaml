# Config file for the project

# GENERAL
niva_project_data_root: "/home/niva/ai4boundaries_data" # TO SET

# PREPROCESSING
download_data:
  ai4boundaries_url: "http://jeodpp.jrc.ec.europa.eu/ftp/jrc-opendata/DRLL/AI4BOUNDARIES"
  ai4boundaries_split_table: "ai4boundaries_ftp_urls_sentinel2_split.csv"
  dl_rate_limit: 5
  dl_retry_limit: 3
  fraction_download: 0.001

create_eopatches:
  # no modifiable parameters

create_npz:
  npz_chunk_size: 20

create_datasets:
  shuffle_buffer_size: 2000
  interleave_cycle_length: 10
  enable_augmentation: true
  use_file_sharding: false
  num_shards: 35

# MODEL
model:
  model_name: "resunet-a"
  input_shape: [256, 256, 4]
  model_config:
    learning_rate: 0.0001
    n_layers: 3
    n_classes: 2
    keep_prob: 0.8
    features_root: 32
    conv_size: 3
    conv_stride: 1
    dilation_rate: [1, 3, 15, 31]
    deconv_size: 2
    add_dropout: true
    add_batch_norm: false
    use_bias: false
    bias_init: 0.0
    padding: "SAME"
    pool_size: 3
    pool_stride: 2
    prediction_visualization: true
    class_weights: null

# TRAINING
training:
  num_epochs: 2
  batch_size: 2
  iterations_per_epoch: 4
  training_type: "SingleWorker"
  use_npz: false
  tf_full_profiling: false
  prefetch_data: true
  enable_data_sharding: true
  chkpt_folder: null
  tensorboard_update_freq: "epoch"
  nsight_batch_profiling: false # TO USE with /scripts/tracing_wrapper.sh
  lustre_llite_dir: "/mnt/lustre-stats/llite" # TO SET if you want to use Nsight lustre plugin

# INFERENCE

# tile download configuration
download_tile:
  input_coords_path: null # TO SET
  tile_name: "input_tile.nc"
  xarray_chunk_size: 2048

# sub-tile split configuration
split_config:
  height: 1000
  width: 1000
  overlap: 0
  num_split: -1 # all sub-tile splits with parameter -1
  begin_x: 0
  begin_y: 0

# prediction configuration
prediction_config:
  model_path: null # TO SET
  height: 1024 # eopatch height + 2 pad_buffer, should by div by 32 filter of model
  width: 1024 # eopatch width + 2 pad_buffer, should by div by 32 filter of model
  n_channels: 4
  pad_buffer: 12
  crop_buffer: 12
  batch_size: 1

# combine sub-tile splits configuration
combine_config:
  scale_factor: 1
  disk_size: 1

# vectorize configuration
vectorize_config:
  shape: [4000, 4000] # scale_factor * scale_factor=2 * EOPatch shape = 1000
  buffer: [200, 200]
  chunk_size: 500
  chunk_overlap: 100
  threshold: 0.6
  cleanup: true
  skip_existing: true
  rows_merging: true

# POSTPROCESSING
postprocess_config:
  simplify_tolerance: 2.5
  smallest_area: 2
  biggest_area: 10000000
  version: 1.3
